# -*- coding: utf-8 -*-
"""Fruit Classification using VGG16 .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16pq7jsGKbdn9jwIw2RebSP7-Pcha_Irk
"""

!pip install kaggle

from google.colab import files

files.upload()

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets list

! kaggle datasets download -d moltean/fruits

! mkdir MMOODDEELL

!unzip fruits.zip -d MMOODDEELL/

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

from keras.layers import Input, Lambda, Dense, Flatten, Dropout
from keras.models import Model
from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator

from sklearn.metrics import confusion_matrix, classification_report

from glob import glob

#set image size
image_size = [32,32]
#get path of both data
train_path = '/content/MMOODDEELL/fruits-360/Training'
valid_path = '/content/MMOODDEELL/fruits-360/Test'
#number of images
image_files = glob(train_path+'/*/*.jp*g')
valid_image_files = glob(valid_path+'/*/*.jp*g')
#number of classes
folders = glob(train_path+'/*')
#add preprocessing layers to vgg
vgg = VGG16(input_shape=(32,32,3),include_top=False)
for layer in vgg.layers:
  layer.trainable = False

vgg.summary()

#layers
x = Flatten()(vgg.output)
x = Dense(1000,activation='relu')(x)

#output layer
prediction = Dense(len(folders),activation='softmax')(x)

#model object
model = Model(inputs=vgg.input,outputs=prediction)

model.summary()

model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])

gen = ImageDataGenerator(
  rotation_range=20,
  width_shift_range=0.1,
  height_shift_range=0.1,
  shear_range=0.1,
  zoom_range=0.2,
  horizontal_flip=True,
  vertical_flip=True,
  preprocessing_function=preprocess_input)

test_gen = gen.flow_from_directory(valid_path,target_size=(image_size))
#label mapping for confusion matrix plot
labels = [None] * len(test_gen.class_indices)
for i,j in test_gen.class_indices.items():
  labels[j] = i

for x, y in test_gen:
  print("min:", x[0].min(), "max:", x[0].max())
  plt.title(labels[np.argmax(y[0])])
  plt.imshow(x[0])
  plt.show()
  
  break

#data generator
train_generator = gen.flow_from_directory(train_path,target_size=(image_size))
valid_generator = gen.flow_from_directory(valid_path,target_size=(image_size))

#FIT MODEL
r = model.fit(train_generator,validation_data=valid_generator,epochs=5,validation_steps=len(valid_image_files) // 32)

#Accuracy graph
plt.plot(r.history['accuracy'],label = 'train accuracy')
plt.plot(r.history['val_accuracy'],label = 'val accuracy')
plt.legend()
plt.show()

#Loss graph
plt.plot(r.history['loss'],label = 'train loss')
plt.plot(r.history['val_loss'],label = 'val loss')
plt.legend()
plt.show()

def get_confusion_matrix(data_path, N):
  # we need to see the data in the same order for both predictions and targets
  
  print("Generating confusion matrix", N)
  predictions = []
  targets = []

  for x, y in gen.flow_from_directory(data_path, target_size=image_size, shuffle=False, batch_size=32* 2):
    p = model.predict(x)
    p = np.argmax(p, axis=1)
    y = np.argmax(y, axis=1)
    predictions = np.concatenate((predictions, p))
    targets = np.concatenate((targets, y))
    if len(targets) >= N:
      break
  cm = confusion_matrix(targets, predictions)
  return predictions, targets, cm

predictions = []
targets = []

predictions, targets, cm = get_confusion_matrix(train_path, len(image_files))
print(cm)
valid_cm = get_confusion_matrix(valid_path, len(valid_image_files))
print(valid_cm)

from sklearn.metrics import classification_report

print(classification_report(predictions,targets))

model.save('fruits-92%-vgg16.h5')

